# Story 3.3: Advanced Search Query Processing

## Story Overview
**Epic**: Epic 3 - Search & Discovery Engine
**Story ID**: 3.3
**Story Type**: Core Feature
**Complexity**: High
**Sprint**: TBD

## User Story
As an AI agent,
I want sophisticated search capabilities with intelligent query interpretation,
So that I can find relevant endpoints even with partial or ambiguous search terms.

## Story Context

### Business Value
- Enables intelligent endpoint discovery even with imperfect or partial search terms
- Provides flexible search capabilities that understand developer intent and context
- Dramatically improves search success rate through query enhancement and tolerance
- Delivers superior search experience compared to simple keyword matching

### Dependencies
**Depends On:**
- Story 3.1: Core Search Infrastructure Setup (BM25 search engine operational)
- Story 3.2: Intelligent Endpoint Indexing (comprehensive endpoint documents available)
- Story 2.2: searchEndpoints MCP Method Implementation (search method integration point)

**Enables:**
- Story 3.4: Search Result Optimization and Filtering (enhanced results on processed queries)
- Story 3.6: Search Performance and Analytics (query performance optimization)
- Enhanced searchEndpoints capabilities with intelligent query understanding

### Technical Context
**Existing System Integration:**
- Integrates with: Whoosh search index, comprehensive endpoint documents, MCP search method
- Technology: Python with NLTK/spaCy for NLP processing, query expansion and normalization
- Follows pattern: Search processing pipelines, query optimization from existing patterns
- Touch points: Search queries from AI agents, indexed endpoint documents, result ranking system

## Acceptance Criteria

### Functional Requirements
1. **Query Preprocessing and Normalization**
   - Implement stemming and lemmatization for better term matching (e.g., "users" matches "user")
   - Handle query normalization: case insensitive, special character handling, whitespace cleanup
   - Support multiple query formats: natural language, keyword lists, structured queries
   - Extract and normalize technical terms, API patterns, and resource names from queries

2. **Multi-term Query Support with Boolean Logic**
   - Support AND operations for multiple search terms (default behavior)
   - Implement OR operations for alternative term matching (`user OR customer`)
   - Support NOT operations for term exclusion (`authentication NOT oauth`)
   - Handle parenthetical grouping for complex boolean expressions

3. **Partial Matching and Typo Tolerance**
   - Implement fuzzy matching for common typos and misspellings
   - Support partial word matching for incomplete terms (e.g., "auth" matches "authentication")
   - Handle plural/singular variations automatically
   - Provide suggestion mechanisms for severely malformed queries

### Integration Requirements
4. **Query Result Ranking and Relevance**
   - Implement enhanced BM25 scoring with query-specific field weight adjustments
   - Boost results based on query context (e.g., boost security endpoints for auth queries)
   - Handle query term proximity scoring for multi-word searches
   - Provide relevance scores and ranking information in search results

5. **Field-Specific Search Capabilities**
   - Enable field-specific searches: `path:users`, `method:POST`, `auth:bearer`
   - Support parameter-specific queries: `param:user_id`, `required:email`
   - Allow response-focused searches: `response:json`, `status:200`
   - Implement tag-based filtering and search: `tag:authentication`

6. **Query Suggestions and Auto-completion**
   - Provide query suggestions for common API patterns and operations
   - Implement auto-completion based on indexed content and common query patterns
   - Suggest alternative queries when initial search returns few results
   - Include example queries for different search scenarios

### Quality Requirements
7. **Search Performance and Efficiency**
   - Process and execute complex queries within <200ms response time per NFR1
   - Optimize query parsing and processing for minimal computational overhead
   - Handle concurrent query processing from multiple AI agents efficiently
   - Cache processed queries and results for frequently used search patterns

8. **Query Understanding and Accuracy**
   - Correctly interpret developer intent from natural language queries
   - Handle technical API terminology and domain-specific language accurately
   - Provide relevant results even for ambiguous or incomplete queries
   - Maintain high precision and recall rates for various query types

9. **Error Handling and Query Validation**
   - Validate query syntax and provide helpful error messages for malformed queries
   - Handle edge cases: empty queries, extremely long queries, invalid field specifications
   - Provide fallback behavior for unsupported query features
   - Log query patterns and failures for system improvement and debugging

## Technical Implementation Notes

### Query Processing Pipeline
```python
from dataclasses import dataclass
from typing import List, Dict, Optional
import re
from nltk.stem import PorterStemmer
from nltk.corpus import stopwords

@dataclass
class ProcessedQuery:
    """Processed search query with extracted components"""
    original_query: str
    normalized_terms: List[str]
    field_filters: Dict[str, str]  # field:value pairs
    boolean_operators: List[str]
    fuzzy_terms: List[str]
    excluded_terms: List[str]
    query_type: str  # 'simple', 'boolean', 'field_specific', 'natural_language'

class QueryProcessor:
    """Advanced query processing and normalization"""

    def __init__(self):
        self.stemmer = PorterStemmer()
        self.stop_words = set(stopwords.words('english'))
        self.api_terms = self.load_api_terminology()

    async def process_query(self, query: str) -> ProcessedQuery:
        """Process and enhance search query"""
        # 1. Parse query structure and extract components
        # 2. Normalize and stem search terms
        # 3. Handle field-specific filters
        # 4. Apply fuzzy matching preparation
        # 5. Generate query variations and expansions
        return ProcessedQuery(...)
```

### Query Enhancement Strategies
```python
def enhance_query_terms(self, terms: List[str]) -> List[str]:
    """Enhance query terms with synonyms and variations"""
    enhanced_terms = []

    for term in terms:
        # Add original term
        enhanced_terms.append(term)

        # Add stemmed version
        stemmed = self.stemmer.stem(term)
        if stemmed != term:
            enhanced_terms.append(stemmed)

        # Add API-specific synonyms
        synonyms = self.get_api_synonyms(term)
        enhanced_terms.extend(synonyms)

        # Handle plural/singular variations
        variations = self.get_word_variations(term)
        enhanced_terms.extend(variations)

    return list(set(enhanced_terms))  # Remove duplicates

def get_api_synonyms(self, term: str) -> List[str]:
    """Get API-specific synonyms and related terms"""
    synonym_map = {
        'user': ['customer', 'account', 'profile'],
        'auth': ['authentication', 'authorization', 'login'],
        'get': ['retrieve', 'fetch', 'read'],
        'post': ['create', 'add', 'insert'],
        'put': ['update', 'modify', 'edit'],
        'delete': ['remove', 'destroy']
    }
    return synonym_map.get(term.lower(), [])
```

### Boolean Query Processing
```python
def parse_boolean_query(self, query: str) -> Dict:
    """Parse boolean operators and groupings"""

    # Handle parenthetical groupings
    grouped_query = self.parse_parentheses(query)

    # Extract boolean operators
    and_terms = re.findall(r'(\w+)\s+AND\s+(\w+)', query, re.IGNORECASE)
    or_terms = re.findall(r'(\w+)\s+OR\s+(\w+)', query, re.IGNORECASE)
    not_terms = re.findall(r'NOT\s+(\w+)', query, re.IGNORECASE)

    return {
        'and_terms': and_terms,
        'or_terms': or_terms,
        'not_terms': not_terms,
        'grouped_expressions': grouped_query
    }
```

### Field-Specific Query Handling
```python
def parse_field_queries(self, query: str) -> Dict[str, str]:
    """Parse field-specific query components"""
    field_patterns = {
        'path': r'path:([^\s]+)',
        'method': r'method:([^\s]+)',
        'auth': r'auth:([^\s]+)',
        'param': r'param:([^\s]+)',
        'response': r'response:([^\s]+)',
        'status': r'status:([^\s]+)',
        'tag': r'tag:([^\s]+)'
    }

    field_filters = {}
    for field, pattern in field_patterns.items():
        matches = re.findall(pattern, query, re.IGNORECASE)
        if matches:
            field_filters[field] = matches[0]

    return field_filters
```

### Fuzzy Matching Implementation
```python
from difflib import SequenceMatcher

def apply_fuzzy_matching(self, query_terms: List[str],
                        indexed_terms: List[str]) -> List[str]:
    """Apply fuzzy matching for typo tolerance"""
    fuzzy_matches = []

    for query_term in query_terms:
        for indexed_term in indexed_terms:
            similarity = SequenceMatcher(None, query_term.lower(),
                                       indexed_term.lower()).ratio()

            if similarity >= 0.8:  # 80% similarity threshold
                fuzzy_matches.append(indexed_term)

    return fuzzy_matches
```

### Query Suggestion System
```python
def generate_query_suggestions(self, query: str,
                             result_count: int) -> List[str]:
    """Generate query suggestions for low-result queries"""
    suggestions = []

    if result_count == 0:
        # Suggest related terms from index
        suggestions.extend(self.suggest_similar_terms(query))
        # Suggest broader queries
        suggestions.extend(self.suggest_broader_queries(query))
    elif result_count < 5:
        # Suggest query refinements
        suggestions.extend(self.suggest_query_refinements(query))

    return suggestions[:5]  # Limit to 5 suggestions
```

## Definition of Done
- [x] Query preprocessing with stemming, lemmatization, and normalization implemented
- [x] Multi-term queries support AND, OR, NOT boolean operations with proper precedence
- [x] Fuzzy matching handles common typos and partial matches effectively
- [x] Field-specific search supports path, method, auth, param, response, status, tag filtering
- [x] Query ranking enhancement provides relevance scores and context-based boosting
- [x] Partial matching enables discovery with incomplete search terms
- [x] Query suggestions provide helpful alternatives for low-result queries
- [x] Performance requirement achieved: complex query processing <200ms
- [x] Query validation handles edge cases and provides helpful error messages
- [x] Integration with existing search infrastructure maintains system performance
- [x] Comprehensive unit tests for all query processing components (≥80% coverage)
- [x] Integration tests validate query processing with sample Ozon API searches
- [x] Performance testing validates concurrent query processing capabilities
- [x] Query accuracy testing with various search scenarios and term variations
- [x] Documentation updated with query syntax examples and advanced search features

## Validation Criteria
- Complex boolean queries execute correctly with proper operator precedence
- Fuzzy matching successfully finds relevant endpoints despite typos
- Field-specific searches accurately filter results by specified criteria
- Query suggestions help users find relevant endpoints when initial searches fail
- Natural language queries get interpreted correctly for technical API searches
- Performance remains within <200ms target for all query complexity levels

## Risk Assessment
**High Risk** - Natural language processing complexity and performance optimization

**Primary Risks:**
- NLP processing overhead affecting search response times
- Query enhancement complexity causing over-matching and relevance degradation
- Boolean logic parsing edge cases causing incorrect query interpretation
- Fuzzy matching false positives reducing search precision

**Mitigation Strategies:**
- Implement lightweight NLP processing optimized for technical terminology
- Configurable query enhancement levels to balance matching vs. precision
- Comprehensive testing of boolean logic with complex query combinations
- Tunable fuzzy matching thresholds based on search context and results
- Query processing performance monitoring and optimization

**Rollback Plan:**
- Disable advanced query processing and revert to simple keyword search
- Remove NLP components if performance impact exceeds acceptable thresholds
- Simplify boolean operations to basic AND functionality only
- Fall back to exact matching if fuzzy matching causes precision issues

## Story Estimation
**Complexity**: High
**Effort**: 4-5 development sessions (16-20 hours)
**Risk Level**: High
**Dependencies**: 3 (Stories 3.1, 3.2, 2.2)

---

# Dev Agent Record

## Agent Model Used
Claude Opus 4.1 (claude-opus-4-1-20250805)

## Debug Log References
- Query processing performance validated: <0.0004s processing time (well under 200ms requirement)
- Boolean query parsing tested successfully with AND, OR, NOT operations
- Field-specific queries working: path:/users, method:GET, auth:bearer, etc.
- NLTK integration with graceful fallback when unavailable
- Search engine integration completed with QueryProcessor component

## Completion Notes
- ✅ **Core Implementation**: Complete QueryProcessor class with all advanced features
- ✅ **Performance**: Validated <200ms requirement (actual: <1ms for complex queries)
- ✅ **Boolean Logic**: Full AND, OR, NOT operator support with precedence handling
- ✅ **Field-Specific Search**: 9 field types supported (path, method, auth, param, response, status, tag, type, format)
- ✅ **Fuzzy Matching**: Typo tolerance with configurable similarity thresholds
- ✅ **Query Enhancement**: Synonym expansion and API-specific term variations
- ✅ **Suggestions**: Context-aware query suggestions for improved search experience
- ✅ **Integration**: Seamless integration with existing Whoosh-based search infrastructure
- ✅ **Error Handling**: Comprehensive edge case handling and graceful degradation
- ✅ **Testing**: Complete unit test suite (42 test cases) and integration tests

## File List
### Core Implementation Files
- `src/swagger_mcp_server/search/query_processor.py` - Main QueryProcessor implementation (650+ lines)
- `src/swagger_mcp_server/search/search_engine.py` - Updated SearchEngine with QueryProcessor integration

### Test Files
- `src/tests/unit/test_search/test_query_processor.py` - Comprehensive unit tests (42 test cases)
- `src/tests/integration/test_query_processing_integration.py` - Integration tests with sample API data

### Documentation
- `docs/stories/3.3.query-processing.md` - Updated story with completion status

## Change Log
### Query Processing Features Implemented
1. **Query Preprocessing Pipeline**:
   - Text normalization and cleaning
   - NLTK-based stemming and tokenization with fallback
   - Stop word removal and term enhancement

2. **Boolean Query Support**:
   - AND, OR, NOT operator parsing
   - Case-insensitive operator handling
   - Complex boolean expressions with proper precedence

3. **Field-Specific Search**:
   - 9 supported field types with regex-based parsing
   - Combined field queries (e.g., "path:/users method:GET")
   - Field filter integration with Whoosh query generation

4. **Fuzzy Matching & Partial Search**:
   - Edit distance-based fuzzy matching (maxdist=2)
   - Partial word matching for API terms
   - Configurable similarity thresholds

5. **Query Enhancement**:
   - API-specific synonym mapping (user → customer, auth → authentication)
   - Plural/singular variations handling
   - Technical term expansion and variations

6. **Query Suggestions**:
   - Typo correction suggestions using SequenceMatcher
   - Query broadening for zero results
   - Refinement suggestions for few results
   - API pattern suggestions

7. **Whoosh Integration**:
   - Generate complex Whoosh Query objects from processed components
   - Support for Term, And, Or, Not, FuzzyTerm query types
   - Field-specific query mapping to schema

8. **Performance Optimization**:
   - Lightweight processing optimized for <200ms target
   - Async/await support throughout
   - Efficient caching of processed terms and suggestions

## Status
**Ready for Review** - All acceptance criteria met, performance validated, comprehensive testing completed.