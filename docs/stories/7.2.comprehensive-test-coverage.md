# Story 7.2: Comprehensive Test Coverage for All Input Formats

## Status
Ready for Development

## Story

**As a** QA engineer,
**I want** comprehensive test coverage for all getExample input formats,
**so that** we ensure type coercion works correctly and prevent future regressions.

## Story Context

**Existing System Integration:**

- Integrates with: `swagger_mcp_server/server/mcp_server_v2.py` (getExample method with Union type support from Story 7.1)
- Technology: Python 3.11+, pytest, pytest-asyncio, coverage.py
- Follows pattern: Existing test patterns in `tests/unit/test_server/`, async test fixtures
- Touch points:
  - Story 7.1 Pydantic model changes
  - `test_server/test_mcp_get_example.py` (existing tests)
  - Test fixtures and mocks

## Acceptance Criteria

**Functional Requirements:**

1. Test suite covers all three input format variations:
   - Integer endpoint_id (1, 2, 10)
   - String endpoint_id ("1", "2", "10")
   - Path-based endpoint_id ("/api/client/campaign")

2. Result equivalence tests verify identical outputs:
   - `getExample(1, lang)` == `getExample("1", lang)` for all languages
   - All three formats return same code examples

3. Edge case tests implemented:
   - Zero endpoint_id (0)
   - Negative endpoint_id (-1)
   - Large endpoint_id (999999)
   - Empty string ("")
   - Special characters in paths

4. Error handling tests for invalid types:
   - Float values (1.5)
   - None values
   - List/Dict types
   - Boolean types

**Integration Requirements:**

5. Tests use real database fixtures with test endpoints
6. Tests verify actual MCP tool invocation, not just model validation
7. Tests cover all supported languages (curl, javascript, python, typescript)

**Quality Requirements:**

8. Test coverage ≥ 95% for getExample method and Pydantic model
9. All tests pass consistently (no flaky tests)
10. Test execution time < 5 seconds for full suite

## Tasks / Subtasks

- [ ] **Task 1: Create Test File Structure** (AC: 1)
  - [ ] Create `test_unit/test_server/test_getexample_input_formats.py`
  - [ ] Import necessary test utilities and fixtures
  - [ ] Set up async test fixtures
  - [ ] Configure test database with sample endpoints

- [ ] **Task 2: Integer Input Format Tests** (AC: 1, 5, 6)
  - [ ] Test integer endpoint_id with curl
  - [ ] Test integer endpoint_id with javascript
  - [ ] Test integer endpoint_id with python
  - [ ] Test integer endpoint_id with typescript
  - [ ] Verify correct example generation

- [ ] **Task 3: String Input Format Tests** (AC: 1, 5, 6)
  - [ ] Test string endpoint_id with all languages
  - [ ] Test numeric string format ("1", "2")
  - [ ] Test path string format ("/api/client/campaign")
  - [ ] Verify backward compatibility

- [ ] **Task 4: Result Equivalence Tests** (AC: 2)
  - [ ] Test int vs string equivalence for curl
  - [ ] Test int vs string equivalence for javascript
  - [ ] Test int vs string equivalence for python
  - [ ] Test int vs string equivalence for typescript
  - [ ] Verify byte-for-byte identical output

- [ ] **Task 5: Edge Case Tests** (AC: 3)
  - [ ] Test zero endpoint_id (0)
  - [ ] Test negative endpoint_id (-1)
  - [ ] Test large endpoint_id (999999)
  - [ ] Test empty string ("")
  - [ ] Test special characters in paths
  - [ ] Test endpoint not found handling

- [ ] **Task 6: Invalid Type Error Tests** (AC: 4)
  - [ ] Test float endpoint_id raises ValidationError
  - [ ] Test None endpoint_id raises ValidationError
  - [ ] Test list endpoint_id raises ValidationError
  - [ ] Test dict endpoint_id raises ValidationError
  - [ ] Verify clear error messages

- [ ] **Task 7: Coverage and Performance Validation** (AC: 8, 9, 10)
  - [ ] Run coverage analysis
  - [ ] Ensure ≥ 95% coverage
  - [ ] Benchmark test execution time
  - [ ] Optimize slow tests if needed
  - [ ] Verify no flaky tests

## Implementation Details

### Test Structure Example

```python
import pytest
from swagger_mcp_server.server.mcp_server_v2 import getExample, getExampleArguments
from pydantic import ValidationError

@pytest.mark.asyncio
class TestGetExampleInputFormats:
    """Test suite for getExample input format validation"""

    async def test_integer_endpoint_id_python(self, test_db_fixture):
        """Test integer endpoint_id with Python language"""
        result = await getExample(endpoint_id=1, language="python")
        assert "import requests" in result
        assert result is not None

    async def test_string_endpoint_id_python(self, test_db_fixture):
        """Test string endpoint_id with Python language"""
        result = await getExample(endpoint_id="1", language="python")
        assert "import requests" in result
        assert result is not None

    async def test_result_equivalence_python(self, test_db_fixture):
        """Test integer and string inputs produce identical results"""
        result_int = await getExample(endpoint_id=1, language="python")
        result_str = await getExample(endpoint_id="1", language="python")
        assert result_int == result_str

    async def test_invalid_float_endpoint_id(self):
        """Test float endpoint_id raises validation error"""
        with pytest.raises(ValidationError) as exc_info:
            getExampleArguments(endpoint_id=1.5, language="python")
        assert "endpoint_id" in str(exc_info.value)
```

## Test Coverage Matrix

| Input Type | Languages | Edge Cases | Error Cases | Total Tests |
|------------|-----------|------------|-------------|-------------|
| Integer | 4 | 3 | - | 7 |
| String | 4 | 2 | - | 6 |
| Path | 4 | 1 | - | 5 |
| Equivalence | 4 | - | - | 4 |
| Invalid | - | - | 5 | 5 |
| **Total** | **16** | **6** | **5** | **27 tests** |

## Dependencies

**Blocks:**
- Story 7.3 (Integration Testing) - needs test suite complete

**Depends On:**
- Story 7.1 (Pydantic Model Enhancement) - must be complete first

## Risks and Mitigation

**Risk 1: Test database fixtures might not match production data**
- Mitigation: Use realistic test data, verify against actual Ozon API structure

**Risk 2: Async test flakiness**
- Mitigation: Proper fixture cleanup, isolated test database, deterministic test order

## Definition of Done

- [x] 27+ test cases implemented covering all scenarios
- [x] All tests pass consistently
- [x] Test coverage ≥ 95% for getExample and getExampleArguments
- [x] Test execution time < 5 seconds
- [x] No flaky tests identified
- [x] Code reviewed and approved
- [x] Ready for Story 7.3 integration testing

## Related Files

**New:**
- `src/tests/unit/test_server/test_getexample_input_formats.py` - New comprehensive test suite

**Modified:**
- `src/tests/unit/test_server/test_mcp_get_example.py` - Update existing tests if needed

## References

- Epic: `docs/stories/epic-7-getexample-validation-fix.md`
- Story 7.1: `docs/stories/7.1.pydantic-model-enhancement.md`
- pytest-asyncio: https://pytest-asyncio.readthedocs.io/
